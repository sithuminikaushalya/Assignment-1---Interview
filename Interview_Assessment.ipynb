{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Assessment  - Engineering Analytics - Dialog Axiata PLC\n",
    "\n",
    "#### Name: < WL Sithumini Kaushalya Amarasinghe >\n",
    "#### E Mail: < amarasimghesithumini@gmail.com >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a)\n",
    "#### Load and assess \"cx_churn_data.csv\" dataset.\n",
    "\n",
    "Explain how data was loaded...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   cx_id                     7043 non-null   object \n",
      " 1   gender                    7043 non-null   object \n",
      " 2   senior_citizen            7043 non-null   object \n",
      " 3   partner                   7043 non-null   object \n",
      " 4   dependents                7042 non-null   object \n",
      " 5   tenure                    7043 non-null   int64  \n",
      " 6   phone_service             7041 non-null   object \n",
      " 7   multiple_connections      7043 non-null   object \n",
      " 8   internet_connection_type  7040 non-null   object \n",
      " 9   device_insurance          7041 non-null   object \n",
      " 10  call_center_support       7039 non-null   object \n",
      " 11  dtv                       7040 non-null   object \n",
      " 12  dtv_viu                   7041 non-null   object \n",
      " 13  account_type              7042 non-null   object \n",
      " 14  e_bill                    7042 non-null   object \n",
      " 15  payment_method            7038 non-null   object \n",
      " 16  monthly_bill              7042 non-null   float64\n",
      " 17  total_bill                7043 non-null   object \n",
      " 18  churn                     7043 non-null   object \n",
      "dtypes: float64(1), int64(1), object(17)\n",
      "memory usage: 1.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cx_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>phone_service</th>\n",
       "      <th>multiple_connections</th>\n",
       "      <th>internet_connection_type</th>\n",
       "      <th>device_insurance</th>\n",
       "      <th>call_center_support</th>\n",
       "      <th>dtv</th>\n",
       "      <th>dtv_viu</th>\n",
       "      <th>account_type</th>\n",
       "      <th>e_bill</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_bill</th>\n",
       "      <th>total_bill</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>HBB</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>prepaid</td>\n",
       "      <td>Yes</td>\n",
       "      <td>app</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>HBB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>postpaid</td>\n",
       "      <td>No</td>\n",
       "      <td>cash</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>HBB</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>prepaid</td>\n",
       "      <td>Yes</td>\n",
       "      <td>cash</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>HBB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>postpaid</td>\n",
       "      <td>No</td>\n",
       "      <td>bank transfer</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>MBB</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>prepaid</td>\n",
       "      <td>Yes</td>\n",
       "      <td>app</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cx_id  gender senior_citizen partner dependents  tenure phone_service  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1            No   \n",
       "1  5575-GNVDE    Male              0      No         No      34           Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2           Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45            No   \n",
       "4  9237-HQITU  Female              0      No         No       2           Yes   \n",
       "\n",
       "  multiple_connections internet_connection_type device_insurance  \\\n",
       "0     No phone service                      HBB               No   \n",
       "1                   No                      HBB              Yes   \n",
       "2                   No                      HBB               No   \n",
       "3     No phone service                      HBB              Yes   \n",
       "4                   No                      MBB               No   \n",
       "\n",
       "  call_center_support dtv dtv_viu account_type e_bill payment_method  \\\n",
       "0                  No  No      No      prepaid    Yes            app   \n",
       "1                  No  No      No     postpaid     No           cash   \n",
       "2                  No  No      No      prepaid    Yes           cash   \n",
       "3                 Yes  No      No     postpaid     No  bank transfer   \n",
       "4                  No  No      No      prepaid    Yes            app   \n",
       "\n",
       "   monthly_bill total_bill churn  \n",
       "0         29.85      29.85    No  \n",
       "1         56.95     1889.5    No  \n",
       "2         53.85     108.15   Yes  \n",
       "3         42.30    1840.75    No  \n",
       "4         70.70     151.65   Yes  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('cx_churn_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the challenges encountered and describe dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b)\n",
    "#### Data cleansing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   cx_id                     7043 non-null   object \n",
      " 1   gender                    7043 non-null   object \n",
      " 2   senior_citizen            7043 non-null   object \n",
      " 3   partner                   7043 non-null   object \n",
      " 4   dependents                7042 non-null   object \n",
      " 5   tenure                    7043 non-null   int64  \n",
      " 6   phone_service             7041 non-null   object \n",
      " 7   multiple_connections      7043 non-null   object \n",
      " 8   internet_connection_type  7040 non-null   object \n",
      " 9   device_insurance          7041 non-null   object \n",
      " 10  call_center_support       7039 non-null   object \n",
      " 11  dtv                       7040 non-null   object \n",
      " 12  dtv_viu                   7041 non-null   object \n",
      " 13  account_type              7042 non-null   object \n",
      " 14  e_bill                    7042 non-null   object \n",
      " 15  payment_method            7038 non-null   object \n",
      " 16  monthly_bill              7042 non-null   float64\n",
      " 17  total_bill                7043 non-null   object \n",
      " 18  churn                     7043 non-null   object \n",
      "dtypes: float64(1), int64(1), object(17)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Drop duplicate rows if any\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Example: Convert 'gender' column to categorical type if not already\n",
    "if df['gender'].dtype != 'object':\n",
    "    df['gender'] = df['gender'].astype('category')\n",
    "\n",
    "# Display the cleaned data\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe steps taken to cleanse the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c)\n",
    "#### Fill in missing values using suitable methods. (If required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12540\\2886833850.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(df[column].median(), inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12540\\2886833850.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(df[column].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Insert code for part (c)\n",
    "# Fill missing values for numerical columns with the median\n",
    "for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[column].fillna(df[column].median(), inplace=True)\n",
    "\n",
    "# Fill missing values for categorical columns with the mode\n",
    "for column in df.select_dtypes(include=['category']).columns:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "# Verify that there are no missing values left\n",
    "missing_values_after = df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe methods used and justify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d)\n",
    "#### Account for class imbalance with suitable methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn\n",
      "No     5174\n",
      "Yes    5174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming df is already loaded and contains the data\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "# Identify categorical features\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Create a ColumnTransformer to apply OneHotEncoding to categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the rest of the features unchanged\n",
    ")\n",
    "\n",
    "# Transform the features\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_transformed, y)\n",
    "\n",
    "# Verify the new class distribution\n",
    "print(y_resampled.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe methods used and justify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (e)\n",
    "#### Train ML model to predict churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8821256038647343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.98      0.77      0.87      1021\n",
      "         Yes       0.82      0.99      0.89      1049\n",
      "\n",
      "    accuracy                           0.88      2070\n",
      "   macro avg       0.90      0.88      0.88      2070\n",
      "weighted avg       0.90      0.88      0.88      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert sparse matrix to dense if necessary\n",
    "if hasattr(X_train, 'toarray'):\n",
    "    X_train = X_train.toarray()\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "# Standardize the feature variables\n",
    "scaler = StandardScaler(with_mean=False)  # Avoid centering sparse matrices\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what happened and elaborate on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer (f)\n",
    "\n",
    "Train an ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the ANN model\n",
    "model_ann = Sequential()\n",
    "model_ann.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_ann.add(Dense(units=32, activation='relu'))\n",
    "model_ann.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_ann.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_ann.evaluate(X_test, y_test)\n",
    "predictions = model_ann.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary outcomes\n",
    "y_pred_ann = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "report_ann = classification_report(y_test, y_pred_ann)\n",
    "\n",
    "print(f\"ANN Accuracy: {accuracy}\")\n",
    "print(report_ann)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what happened and elaborate on model performance. \n",
    "Compare (e) model performance with (f)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8999ca217b2fa3fb8875d9227edfd6c20266cf632b7380cda2ffe3df3689d7c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
